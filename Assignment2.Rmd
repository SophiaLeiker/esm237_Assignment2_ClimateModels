---
title: "Climate model_demo"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## How to Read Climate Model Data in R

This is a brief introduction to the R libraries and commands you'll need to read in and analyze output from climate/Earth system models. There are many other resources out there, if you'd like more information! I particularly like this set of tutorials, from the "R for Earth System Science" course at the University of Oregon:
https://pjbartlein.github.io/REarthSysSci/netCDF.html

The commands needed for manipulating netCDF files are contained in the "ncdf4" package in R, make sure this is loaded!

This example assumes that we have already downloaded a netCDF file; I will provide two different examples here, each for a monthly surface air temperature file.

1. Community Earth System Model (CESM) version 1

The first example uses surface temperature ("TS") from a CESM1 simulation run over 1920-2005. The naming conventions for the CESM files are slightly different from the CMIP6 data we looked at in class: the bits of the filename tell you things about how the model was configured (for example "f09_g16" refers to the model resolution, "B20TR" means it's a coupled 'transient' simulation with time-varying CO2) that you don't really need to worry about here. The important bits are:
- the number that appears right before "cam.h0", this is the ensemble member number (equivalent to the "r1i1p1" string in a CMIP filename); and
- the date string at the end, in this case "192001-200512"; this is the range of years contained in the file, and will vary depending on the model and simulation.


2. Coupled Model Intercomparison Project (CMIP6)

The second example reads in surface temperature ("tas") from an arbitrary CMIP6 model: I picked the E3SM-1-0 model since it's another commonly used example. I've selected two files here because E3SM stored its output in smaller time "chunks" than our CESM1 example above, and I wanted to show you how to go about stitching together data from multiple files since that's a pretty common task one needs to carry out when working with these models. 


NOTE: The "ncpath" variable below should be set to the directory where the netCDF file is located on YOUR computer!

```{r readcesm}
library(lubridate)
library(ggplot2)
library(tidyverse)
library(chron)
library(ncdf4)
library(RColorBrewer)
library(lattice)
library(abind)
library(here)
library(reshape2)

# path and filename for data
ncpath <- here("data")
ncname <- "1g_tas_historical_1850-1900.nc"  # CESM1 filename
ncfname <- paste(ncpath, ncname, sep="/")
dname <- "TS"  # this is the name of the variable you want to look at

ncin <- nc_open(ncfname)
#print(ncin)
print(ncfname)
```


Using the print command, we can see some of the basic information about the data ("metadata"), like units, coordinates, etc.

The next thing we need to do is to actually read in the data! This is done with the "ncvar_get" command. Let's start with the time, latitude, and longitude coordinates: since TS is a two-dimensional variable, these are the only coordinates needed. If you want to work with 3D fields like ocean temperature, winds, or soil moisture, then you'll also need an additional vertical coordinate (again, "print" is your friend to find out what those are called).

The following commands read in the longitude and latitude information, and store the lengths of each axis in variables 'nlon' and 'nlat'.

```{r readcoords}
lon <- ncvar_get(ncin,"lon")
nlon <- dim(lon)
lat <- ncvar_get(ncin,"lat")
nlat <- dim(lat)

head(lat)
head(lon)

```

Next we'll do the same thing with the time coordinate: this one takes a bit more attention, since the time units must be converted to R date format. Also an important note: if you're working with multiple climate models, the time units are probably different!! 

```{r readtime}
time <- ncvar_get(ncin,"time")
tunits <- ncatt_get(ncin,"time","units")
nt <- dim(time)

print(tunits)
```

For CESM, the units of time are "days since 1920-01-01". Making things more complicated: the CESM model *calendar* doesn't use leap years! So I've used the below technique to convert this weird time data into something that R can work with more easily.

The units of time are stored in "tunits", which contains two fields: hasatt, a logical variable, and units, the actual units themselves. The "value" field is simply a string, which we can use the "strsplit" function to split into parts and retrieve the portions of the starting date: in this case, 1920, 1 (January), and 1 (the first day of the month). I store these in the variables "tyear", "tmonth", and "tday" respectively.

Why do this? Because then that year/month/day information can be supplied as an "origin" to the R chron command, to generate a standard R-format time vector.

The full set of R commands thus described are:


```{r formattime}
tustr <- strsplit(tunits$value, " ")
tdstr <- strsplit(unlist(tustr)[3], "-")
tmonth <- as.integer(unlist(tdstr)[2])
tday <- as.integer(unlist(tdstr)[3])
tyear <- as.integer(unlist(tdstr)[1])
rtime <- chron(time,origin=c(tmonth, tday, tyear))
```

OK now let's read in the CESM temperature data! This may take a while, depending on your computer and the size of the data file. It's also a good idea to get some attributes of the data: the full name ("long_name"), units, and the value used to fill in places where there are no data ("_FillValue"). 

```{r readtemp}
tas <- ncvar_get(ncin, "tas") #SOPHIA NOTES : I changed this to "tas"
dlname <- ncatt_get(ncin,"tas","long_name") #SOPHIA NOTES: I CHANGED dname to "tas" here
dunits <- ncatt_get(ncin,"tas","units") #SOPHIA NOTES: I CHANGED dname to "tas" here
fillvalue <- ncatt_get(ncin,"tas","_FillValue") #SOPHIA NOTES: I CHANGED dname to "tas" here
```

Now we have temperature loaded in and ready to be processed; the dimensions of the "TS" array are [lat x lon x time]. We can make a time slice through the data to see a map of surface temperature at a particular time: say, January 1920 (the first entry in the file).

```{r slice}
m <- 1
tmp_slice <- tas[,,m]-273.15     # convert Kelvin to Celsius
# levelplot of the slice
grid <- expand.grid(lon=lon, lat=lat)
cutpts <- c(-50,-40,-30,-20,-10,0,10,20,30,40,50)
levelplot(tmp_slice ~ lon * lat, data=grid, at=cutpts, cuts=11, pretty=T, 
  col.regions=(rev(brewer.pal(10,"RdBu"))))
```

Another common calculation is the time series of regionally averaged data from a particular location of interest (think HW 1, but with model output). To do this, select the parts of the data matrix corresponding to the latitudes and longitudes in your region (note: it's also possible to do this with a shapefile, but that was a longer example than we have time for now).

Let's plot a box covering parts of southern California: 32-35N, 117-119W. **note: you'll also need to pay attention to whether the longitudes in the model are given in degrees E (0 to 360) or degrees W and E (-180 to 180). CESM uses 0-360 coordinates, so the longitude range we want is 241-243E.

The R 'apply' function lets us compute the average over the region easily; here we specify 3 as the dimension over which to apply the mean, and this applies the average over all values corresponding to each time. As a bonus, I've also used the 'group_by' and 'summarize' functions to create annual temperatures from this data before plotting the time series; you can also just plot the raw monthly values if you prefer.

```{r getregion}
#THIS IS LUCAS'S CODE FOR THE NEXT FEW LINES
#### PUT LAT AND LONG READINGS TO SPECIFY AREA HERE
##These latitutde and longitute ranges align with Concordian Station up in Antarctica 
lats=which(lat >= -78.5 & lat <= -71.7) # insert lattitude and longitude readings here!
lons=which(lon >= 116.8 & lon <= 129.9)

tsavg <- apply(tas[lons,lats,],3,mean)

clim <- data.frame(time=rtime, tsavg=tsavg)
yrclim = clim %>% group_by(year(rtime)) %>% summarize(Tann=mean(tsavg))
yrclim$dt = unique(year(rtime))

ggplot(yrclim, aes(dt, Tann-273.15))+geom_point()+labs(y="Concordia Station Temperature", x="Year")+ geom_smooth(method="lm")
```

```{r}
#THIS IS LUCAS'S CODE TO WRITE HISTORICAL 1 DATA
#I GUESS WE MIGHT HAVE TO RUN THIS 4 TIMES IN ORDER TO GET 4 HISTORICAL/DIFFERENT DATASETS?
#KINDA CONFUSED WHAT IS HAPPENING HERE
clim_full <- clim %>%
  mutate(year = year(rtime)) %>% 
  mutate(month = month(rtime)) %>% 
  mutate(date = as.Date(paste(year, month, "01", sep = "-"))) %>% 
  mutate(average_tas_c = tsavg - 273.15) %>% 
  dplyr::select(-tsavg, -time, -year, -month) #%>% 
  # separate(col = time, into = c("date", "tod"), sep = " ") %>% 
  # mutate(date = mdy(date)) %>% 
  # mutate(month = month(date, label = TRUE))
  # dplyr::select(-tsavg, -tod) %>% 
  #write_csv(file = "historical1" , col_names = TRUE, append = TRUE)

```



#SOPHIA ENEDED CODING HERE!!!! ###########


## Sophia - all of our code is below. The final code chunk is our ggplot. We need to make sure the regression is working properly and fix aesthetics.

Part 2: E3SM Data

Here is a brief demonstration of how to read in data from E3SM; once you do, you can use the exact same techniques as in Part 1 to create time series plots, maps, etc. Here I'm going to read in the two files into two different variables - you can also build a loop to do things if you like!

```{r reade3sm}
# path and filename for data
ncpath <- here("data")   # path (directory)
dname <- "tas"  # this is the name of the variable you want to look at

#historical data from NASA models GISS-E2.1-G and NASA GISS-E2.1-H
#note the f_ before each one because this is just file name 
f_e2_1_g_1850_1900 <- "1g_tas_historical_1850-1900.nc"  # E3SM filename
f_e2_1_g_1901_1950 <- "1g_tas_historical_1901-1950.nc"  # E3SM filename
f_e2_1_g_1951_2000 <- "1g_tas_historical_1951-2000.nc"  # E3SM filename
f_e2_1_g_2001_2014 <- "1g_tas_historical_2001-2014.nc"  # E3SM filename

f_e2_1_h_1850_1900 <- "1h_tas_historical_1850-1900.nc"  # E3SM filename
f_e2_1_h_1901_1950 <- "1h_tas_historical_1901-1950.nc"  # E3SM filename
f_e2_1_h_1951_2000 <- "1h_tas_historical_1951-2000.nc"  # E3SM filename
f_e2_1_h_2001_2014 <- "1h_tas_historical_2001-2014.nc"  # E3SM filename

#predictive data from ssp1 rcp 26 and ssp5 rcp 85 from both NASA models
f_e2_1_g_ssp126_2015_2050 <- "1g_tas_ssp126_2015-2050.nc" # E3SM filename
f_e2_1_g_ssp126_2051_2100 <- "1g_tas_ssp126_2051-2100.nc" # E3SM filename
f_e2_1_g_ssp585_2015_2050 <- "1g_tas_ssp585_2015-2050.nc" # E3SM filename
f_e2_1_g_ssp585_2051_2100 <- "1g_tas_ssp585_2051-2100.nc" # E3SM filename

f_e2_1_h_ssp126_2015_2050 <- "1h_tas_ssp126_2015-2050.nc" # E3SM filename
f_e2_1_h_ssp126_2051_2100 <- "1h_tas_ssp126_2051-2100.nc" # E3SM filename
f_e2_1_h_ssp585_2015_2050 <- "1h_tas_ssp585_2015-2050.nc" # E3SM filename
f_e2_1_h_ssp585_2051_2100 <- "1h_tas_ssp585_2051-2100.nc" # E3SM filename

#creating strings for file paths.. Note the p_ before each object because it is just a path name

#historical data:
p_e2_1_g_1850_1900 <- paste(ncpath, f_e2_1_g_1850_1900, sep="/")
p_e2_1_g_1901_1950 <- paste(ncpath, f_e2_1_g_1901_1950, sep="/")
p_e2_1_g_1951_2000 <- paste(ncpath, f_e2_1_g_1951_2000, sep="/")
p_e2_1_g_2001_2014 <- paste(ncpath, f_e2_1_g_2001_2014, sep="/")

p_e2_1_h_1850_1900 <- paste(ncpath, f_e2_1_h_1850_1900, sep="/")
p_e2_1_h_1901_1950 <- paste(ncpath, f_e2_1_h_1901_1950, sep="/")
p_e2_1_h_1951_2000 <- paste(ncpath, f_e2_1_h_1951_2000, sep="/")
p_e2_1_h_2001_2014 <- paste(ncpath, f_e2_1_h_2001_2014, sep="/")

#predictive data:
p_e2_1_g_ssp126_2015_2050 <- paste(ncpath, f_e2_1_g_ssp126_2015_2050, sep="/")
p_e2_1_g_ssp126_2051_2100 <- paste(ncpath, f_e2_1_g_ssp126_2051_2100, sep="/")
p_e2_1_g_ssp585_2015_2050 <- paste(ncpath, f_e2_1_g_ssp585_2015_2050, sep="/")
p_e2_1_g_ssp585_2051_2100 <- paste(ncpath, f_e2_1_g_ssp585_2051_2100, sep="/")

p_e2_1_h_ssp126_2015_2050 <- paste(ncpath, f_e2_1_h_ssp126_2015_2050, sep="/")
p_e2_1_h_ssp126_2051_2100 <- paste(ncpath, f_e2_1_h_ssp126_2051_2100, sep="/")
p_e2_1_h_ssp585_2015_2050 <- paste(ncpath, f_e2_1_h_ssp585_2015_2050, sep="/")
p_e2_1_h_ssp585_2051_2100 <- paste(ncpath, f_e2_1_h_ssp585_2051_2100, sep="/")

#creating objects after opening files... this is a lot 
#historical data 
e2_1_g_1850_1900 <- nc_open(p_e2_1_g_1850_1900)
e2_1_g_1901_1950 <- nc_open(p_e2_1_g_1901_1950)
e2_1_g_1951_2000 <- nc_open(p_e2_1_g_1951_2000)
e2_1_g_2001_2014 <- nc_open(p_e2_1_g_2001_2014)

e2_1_h_1850_1900 <- nc_open(p_e2_1_h_1850_1900)
e2_1_h_1901_1950 <- nc_open(p_e2_1_h_1901_1950)
e2_1_h_1951_2000 <- nc_open(p_e2_1_h_1951_2000)
e2_1_h_2001_2014 <- nc_open(p_e2_1_h_2001_2014)
  
#predictive data 
e2_1_g_ssp126_2015_2050 <- nc_open(p_e2_1_g_ssp126_2015_2050)
e2_1_g_ssp126_2051_2100 <- nc_open(p_e2_1_g_ssp126_2051_2100)
e2_1_g_ssp585_2015_2050 <- nc_open(p_e2_1_g_ssp585_2015_2050)
e2_1_g_ssp585_2051_2100 <- nc_open(p_e2_1_g_ssp585_2051_2100)

e2_1_h_ssp126_2015_2050 <- nc_open(p_e2_1_h_ssp126_2015_2050)
e2_1_h_ssp126_2051_2100 <- nc_open(p_e2_1_h_ssp126_2051_2100)
e2_1_h_ssp585_2015_2050 <- nc_open(p_e2_1_h_ssp585_2015_2050)
e2_1_h_ssp585_2051_2100 <- nc_open(p_e2_1_h_ssp585_2051_2100)

#lol 
```

Now once again, we read in the time coordinate information as we did for CESM. Since we happen to know that the second file begins immediately after the first one, we also know that we can concatenate the time information from the two files to get a time series of the full time period:

```{r reade3smtime}
#creating time series - we just need to do this once right? Or we can just copy this code for difference strings to reference if they're needed

time1 <- ncvar_get(e2_1_g_1850_1900,"time")
time2 <- ncvar_get(e2_1_g_1901_1950,"time")
time3 <- ncvar_get(e2_1_g_1951_2000,"time")
time4 <- ncvar_get(e2_1_g_2001_2014,"time")
time5 <- ncvar_get(e2_1_g_ssp585_2015_2050,"time")
time6 <- ncvar_get(e2_1_g_ssp585_2051_2100,"time")

#conconate time series (creating multiple: one for history, one for predictions, one for total)
timehistory=c(time1,time2,time3,time4)
timefuture=c(time5,time6)
timetotal=c(time1,time2,time3,time4,time5,time6)

#get units for reference - it's the same for each object
tunits <- ncatt_get(e2_1_g_ssp585_2051_2100,"time","units")

```

Notice that the units of time are now different! E3SM uses a calendar which begins in 1850, rather than 1920. But we can still use the same method of splitting the units string, then giving it to 'chron' to make a time that works.

```{r process_e3smtime}

rtime=seq.Date(as.Date("1850/01/01"),as.Date("2100/12/01"),by="months")

```


You can use concatenation to stick the temperature data together as well: here I'm using the "abind" package to do this, where the "along" argument tells R which dimension to concatentate the arrays along. Whether or not you choose to do this is up to you - for some applications it will be more necessary than others. You can also regionally average the data from each file individually, then concatenate those average time series... there are lots of possibilities!

```{r read_e3smtemp}
#extracting historical tas data 
tas_e2_1_g_1850_1900 <- ncvar_get(e2_1_g_1850_1900, "tas")
tas_e2_1_g_1901_1950 <- ncvar_get(e2_1_g_1901_1950, "tas")
tas_e2_1_g_1951_2000 <- ncvar_get(e2_1_g_1951_2000, "tas")
tas_e2_1_g_2001_2014 <- ncvar_get(e2_1_g_2001_2014, "tas")

tas_e2_1_h_1850_1900 <- ncvar_get(e2_1_h_1850_1900, "tas")
tas_e2_1_h_1901_1950 <- ncvar_get(e2_1_h_1901_1950, "tas")
tas_e2_1_h_1951_2000 <- ncvar_get(e2_1_h_1951_2000, "tas")
tas_e2_1_h_2001_2014 <- ncvar_get(e2_1_h_2001_2014, "tas")

#extracting predicted tas data 
tas_e2_1_g_ssp126_2015_2050 <- ncvar_get(e2_1_g_ssp126_2015_2050, "tas")
tas_e2_1_g_ssp126_2051_2100 <- ncvar_get(e2_1_g_ssp126_2051_2100, "tas")
tas_e2_1_g_ssp585_2015_2050 <- ncvar_get(e2_1_g_ssp585_2015_2050, "tas")
tas_e2_1_g_ssp585_2051_2100 <- ncvar_get(e2_1_g_ssp585_2051_2100, "tas")


tas_e2_1_h_ssp126_2015_2050 <- ncvar_get(e2_1_h_ssp126_2015_2050, "tas")
tas_e2_1_h_ssp126_2051_2100 <- ncvar_get(e2_1_h_ssp126_2051_2100, "tas")
tas_e2_1_h_ssp585_2015_2050 <- ncvar_get(e2_1_h_ssp585_2015_2050, "tas")
tas_e2_1_h_ssp585_2051_2100 <- ncvar_get(e2_1_h_ssp585_2051_2100, "tas")

#binding historical tas data

tas_e2_1_g_ssp126 = abind(
  tas_e2_1_g_1850_1900,
  tas_e2_1_g_1901_1950,                              
  tas_e2_1_g_1951_2000,
  tas_e2_1_g_2001_2014,
  tas_e2_1_g_ssp126_2015_2050,
  tas_e2_1_g_ssp126_2051_2100)


tas_e2_1_g_ssp585 = abind(
  tas_e2_1_g_1850_1900,
  tas_e2_1_g_1901_1950,                              
  tas_e2_1_g_1951_2000,
  tas_e2_1_g_2001_2014,
  tas_e2_1_g_ssp585_2015_2050,
  tas_e2_1_g_ssp585_2051_2100)


tas_e2_1_h_ssp126 = abind(
  tas_e2_1_h_1850_1900,
  tas_e2_1_h_1901_1950,                              
  tas_e2_1_h_1951_2000,
  tas_e2_1_h_2001_2014,
  tas_e2_1_h_ssp126_2015_2050,
  tas_e2_1_h_ssp126_2051_2100)

tas_e2_1_h_ssp585 = abind(
  tas_e2_1_h_1850_1900,
  tas_e2_1_h_1901_1950,                              
  tas_e2_1_h_1951_2000,
  tas_e2_1_h_2001_2014,
  tas_e2_1_h_ssp585_2015_2050,
  tas_e2_1_h_ssp585_2051_2100)


```


The following commands read in the longitude and latitude information, and store the lengths of each axis in variables 'nlon' and 'nlat'.

```{r readcoords}
lon <- ncvar_get(e2_1_g_1850_1900,"lon")
nlon <- dim(lon)
lat <- ncvar_get(e2_1_g_1850_1900,"lat")
nlat <- dim(lat)

head(lat)
head(lon)

#Specify latitude and longitude and get averages 
##These latitutde and longitute ranges align with Concordian Station up in Antarctica 
lats=which(lat >= -78.5 & lat <= -71.7) # insert lattitude and longitude readings here!
lons=which(lon >= 116.8 & lon <= 129.9)

```



```{r}
#get averages 

tsavg_e2_1_g_ssp126 <- apply(tas_e2_1_g_ssp126[lons,lats,],3,mean)
tsavg_e2_1_g_ssp585 <- apply(tas_e2_1_g_ssp585[lons,lats,],3,mean)

tsavg_e2_1_h_ssp126 <- apply(tas_e2_1_h_ssp126[lons,lats,],3,mean)
tsavg_e2_1_h_ssp585 <- apply(tas_e2_1_h_ssp585[lons,lats,],3,mean)

```


```{r}
#creating dataframes 
monthly_clim_e2_1_g_ssp126 <- data.frame(time=timetotal, tsavg=tsavg_e2_1_g_ssp126)
monthly_clim_e2_1_g_ssp585 <- data.frame(time=timetotal, tsavg=tsavg_e2_1_g_ssp585)

monthly_clim_e2_1_h_ssp126 <- data.frame(time=timetotal, tsavg=tsavg_e2_1_h_ssp126)
monthly_clim_e2_1_h_ssp585 <- data.frame(time=timetotal, tsavg=tsavg_e2_1_h_ssp585)
```

```{r}
yrly_clim_e2_1_g_ssp126 = monthly_clim_e2_1_g_ssp126 %>% group_by(year(rtime))%>%
summarize(e2_1_g_ssp126=mean(tsavg)) 

yrly_clim_e2_1_g_ssp585 = monthly_clim_e2_1_g_ssp585 %>% group_by(year(rtime))%>%
summarize(e2_1_g_ssp585=mean(tsavg)) 

yrly_clim_e2_1_h_ssp126 = monthly_clim_e2_1_h_ssp126 %>% group_by(year(rtime))%>%
summarize(e2_1_h_ssp126=mean(tsavg)) 

yrly_clim_e2_1_h_ssp585 = monthly_clim_e2_1_h_ssp585 %>% group_by(year(rtime))%>%
summarize(e2_1_h_ssp585=mean(tsavg)) 


```

```{r}
#melting values and binding together
melt_yrly_clim_e2_1_g_ssp126 <- melt(yrly_clim_e2_1_g_ssp126, id.vars = "year(rtime)",variable.name = "dataset", value.name = "average_temp")
melt_yrly_clim_e2_1_g_ssp126

melt_yrly_clim_e2_1_g_ssp585 <- melt(yrly_clim_e2_1_g_ssp585, id.vars = "year(rtime)",variable.name = "dataset", value.name = "average_temp")
melt_yrly_clim_e2_1_g_ssp126

melt_yrly_clim_e2_1_h_ssp126 <- melt(yrly_clim_e2_1_h_ssp126, id.vars = "year(rtime)",variable.name = "dataset", value.name = "average_temp")
melt_yrly_clim_e2_1_g_ssp126

melt_yrly_clim_e2_1_h_ssp585 <- melt(yrly_clim_e2_1_h_ssp585, id.vars = "year(rtime)",variable.name = "dataset", value.name = "average_temp")
melt_yrly_clim_e2_1_g_ssp126

combined_climate_data_melted <- rbind(melt_yrly_clim_e2_1_g_ssp126,melt_yrly_clim_e2_1_g_ssp585,melt_yrly_clim_e2_1_h_ssp126,melt_yrly_clim_e2_1_h_ssp585)

combined_climate_data <- pivot_wider(combined_climate_data_melted, names_from = dataset, values_from = average_temp)
combined_climate_data
```




```{r}
# plot results
# WE STILL NEED TO ADJUST THESE COLORS AND ADD A LEGEND FOR MODEL TYPE AND SCENARIO. WE ALSO NEED TO MAKE SURE THAT THE REGRESSION IS WORKING CORRECTLY

plot_output <- ggplot() +
  geom_line(data = yrly_clim_e2_1_g_ssp126, aes(x = 1850:2100, y = e2_1_g_ssp126 - 273.15, color = 'NASA GISS-E2.1-G SSP126')) +
  geom_line(data = yrly_clim_e2_1_g_ssp585, aes(x = 1850:2100, y = e2_1_g_ssp585 - 273.15, color = 'NASA GISS-E2.1-G SSP585')) +
  geom_line(data = yrly_clim_e2_1_h_ssp126, aes(x = 1850:2100, y = e2_1_h_ssp126 - 273.15, color = 'NASA GISS-E2.1-H SSP126')) +
  geom_line(data = yrly_clim_e2_1_h_ssp585, aes(x = 1850:2100, y = e2_1_h_ssp585 - 273.15, color = 'NASA GISS-E2.1-H SSP585')) +
  labs(y = "Concordia Station Temperature (degrees C)", x = "Year", title = "Mean Surface Air Temperature Change in Concordia Station, Antartica", subtitle = "Models Used: NASA GISS-E2.1-G and NASA GISS-E2.1-H", caption = "Smoothing Method Employed: Linear Regression", color = "Legend") + 
  geom_smooth(method = "lm") +
  geom_vline(xintercept = 2014, linetype = "dashed") + 
  scale_color_manual(values = c('blue', 'cadetblue3', 'darkgoldenrod1', 'chocolate1')) +
  theme_classic() +
  theme(plot.title = element_text(hjust = 0.5), 
        legend.position = "right", 
        legend.title = element_text(size = 14, face = "bold"),
        legend.text = element_text(size = 12),
        legend.key.size = unit(1.5, "lines"),
        legend.margin = margin(t = 0, b = 0, r = 10, l = 10),
        legend.box.just = "right")

plot_output

# Save the plot as a jpeg file in a folder called "plots"
folder_name <- "plots"
file_name <- "plot_output1.jpg"
file_path <- file.path(getwd(), folder_name, file_name)
ggsave(filename = file_path, plot = plot_output, width = 12, height = 7)

```




